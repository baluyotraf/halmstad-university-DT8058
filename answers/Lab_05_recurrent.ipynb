{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name: Raffaello Baluyot\n",
    "## Course: DT8058"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1 style=\"font-size:40px;\">Regression using Recurrent Neural Networks</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to this lab session! Today, we will be diving into the fascinating world of Recurrent Neural Networks (RNNs) and exploring their use in regression tasks.\n",
    "\n",
    "By the end of this lab session, you will be able to:\n",
    "\n",
    "* Understand the basic concepts behind Recurrent Neural Networks and how they work.\n",
    "* Implement different architectures to include recurrent neural networks.\n",
    "* Apply these RNN architectures to solve regression problems.\n",
    "* Evaluate the performance of your models and understand their strengths and limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a gpu\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import cv2\n",
    "from collections import OrderedDict\n",
    "import copy\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "torch.set_default_device(device)\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert angles to 2D vectors\n",
    "def angle_to_vector_np(angles_rad):\n",
    "    return np.cos(angles_rad), np.sin(angles_rad)\n",
    "\n",
    "\n",
    "# Convert degrees to radians\n",
    "def deg_to_rad(deg):\n",
    "    return deg * np.pi / 180\n",
    "\n",
    "\n",
    "# Convert radians to degrees\n",
    "def rad_to_deg(rad):\n",
    "    return rad * 180 / np.pi\n",
    "\n",
    "\n",
    "# Convert angles to 2D vectors\n",
    "def angle_to_vector(angles):\n",
    "    angles_rad = deg_to_rad(angles)\n",
    "    return torch.cos(angles_rad), torch.sin(angles_rad)\n",
    "\n",
    "\n",
    "# Convert 2D vectors to angles\n",
    "def vector_to_angle(vectors):\n",
    "    return rad_to_deg(torch.atan2(vectors[1], vectors[0]))\n",
    "\n",
    "\n",
    "# Convert 2D vectors to angles\n",
    "def vector_to_angle_np(vectors):\n",
    "    return rad_to_deg(np.arctan2(vectors[1], vectors[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "def animate_datapoint(x, y):\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Angle: {:.1f}\".format(vector_to_angle_np(y)))\n",
    "    ims = []\n",
    "    for frame in x:\n",
    "        if isinstance(frame, torch.Tensor):\n",
    "            frame = frame.permute(1, 2, 0).numpy() * 255\n",
    "        im = plt.imshow(frame.astype(np.uint8))\n",
    "        ims.append([im])\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=100, repeat_delay=1000)\n",
    "    return ani\n",
    "\n",
    "\n",
    "def animate_datapoint_with_direction(x, y, center, pred=None, pred_color=\"red\"):\n",
    "    \"\"\"\n",
    "    This function creates an animation of a data point with a direction arrow. Use this function to visualize the data points in the training, validation, and test sets.\n",
    "    You can also use this function to visualize the predictions of your model, by providing the predicted direction vector as the `pred` parameter.\n",
    "    In case the object color is interfering with the visibility of the direction arrow, you can change the color of the predicted direction arrow using the `pred_color` parameter.\n",
    "\n",
    "    Parameters:\n",
    "    x (array-like or torch.Tensor): The frames to be animated. If frames are torch.Tensor, they will be converted to numpy arrays.\n",
    "    y (array-like): The direction vector for the arrow in the animation.\n",
    "    center (tuple): The starting point (center) of the arrow.\n",
    "    pred (array-like, optional): The predicted direction vector for the arrow in the animation. If provided, an additional arrow showing the predicted direction will be drawn. Defaults to None.\n",
    "    pred_color (str, optional): The color of the predicted direction arrow. Defaults to \"red\".\n",
    "\n",
    "    Returns:\n",
    "    matplotlib.animation.ArtistAnimation: The resulting animation object.\n",
    "    \"\"\"\n",
    "\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Angle: {:.1f}\".format(vector_to_angle_np(y)))\n",
    "\n",
    "    ims = []\n",
    "    for frame in x:\n",
    "        if isinstance(frame, torch.Tensor):\n",
    "            frame = frame.permute(1, 2, 0).numpy() * 255\n",
    "        im = plt.imshow(frame.astype(np.uint8))\n",
    "        arrow = plt.arrow(\n",
    "            center[0],\n",
    "            center[1],\n",
    "            y[0] * 4,\n",
    "            y[1] * -4,\n",
    "            head_width=3,\n",
    "            head_length=5,\n",
    "            fc=\"black\",\n",
    "            ec=\"black\",\n",
    "        )\n",
    "        if pred is not None:\n",
    "            arrow_pred = plt.arrow(\n",
    "                center[0],\n",
    "                center[1],\n",
    "                pred[0] * 4,\n",
    "                pred[1] * -4,\n",
    "                head_width=3,\n",
    "                head_length=5,\n",
    "                fc=pred_color,\n",
    "                ec=pred_color,\n",
    "            )\n",
    "            ims.append([im, arrow, arrow_pred])\n",
    "        else:\n",
    "            ims.append([im, arrow])\n",
    "\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=100, repeat_delay=1000)\n",
    "    return ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(\n",
    "    num_samples,\n",
    "    canvas_size=(64, 64),\n",
    "    shapes=[\"circle\", \"triangle\", \"square\"],\n",
    "    colors={\n",
    "        \"blue\": (255, 0, 0),\n",
    "        \"yellow\": (0, 255, 255),\n",
    "        \"red\": (0, 0, 255),\n",
    "        \"gray\": (128, 128, 128),\n",
    "        \"green\": (0, 255, 0),\n",
    "        \"purple\": (255, 0, 255),\n",
    "    },\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates a dataset of random shapes moving in a straight line in random directions.\n",
    "\n",
    "    Parameters:\n",
    "    num_samples (int): The number of samples to generate.\n",
    "    canvas_size (tuple): The size of the canvas for each sample. Defaults to (64, 64).\n",
    "    shapes (list): The shapes to be used in the dataset. Defaults to [\"circle\", \"triangle\", \"square\"].\n",
    "    num_frames (int): The number of frames for each sample. Defaults to 30.\n",
    "    colors (dict): The colors to be used for the shapes. Defaults to a dictionary of BGR color values.\n",
    "    step_size (float): The step size for the movement of the shapes. Defaults to 0.5.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing the following elements:\n",
    "        - dataset (numpy.ndarray): The generated dataset. Shape is (num_samples, num_frames, canvas_size[0], canvas_size[1], 3).\n",
    "        - labels (numpy.ndarray): The labels for each sample. Shape is (num_samples,).\n",
    "        - centers (list): The center positions for each shape.\n",
    "    \"\"\"\n",
    "\n",
    "    labels_list = []\n",
    "    centers_list = []\n",
    "    shapes_list = []\n",
    "    angles_deg_list = []\n",
    "    sizes_list = []\n",
    "    colors_list = []\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        shape = np.random.choice(shapes)\n",
    "        position = np.random.rand(2) * (np.array(canvas_size) - 1)\n",
    "        size = np.random.randint(4, 10)\n",
    "        angle_deg = np.random.uniform(0, 360)\n",
    "        angle_rad = np.radians(angle_deg)\n",
    "        color = colors[np.random.choice(list(colors.keys()))]\n",
    "        colors_list.append(color)\n",
    "\n",
    "        labels_list.append(angle_to_vector_np(angle_rad))\n",
    "        centers_list.append(position.copy())\n",
    "        shapes_list.append(shape)\n",
    "        angles_deg_list.append(angle_deg)\n",
    "        sizes_list.append(size)\n",
    "\n",
    "    return (\n",
    "        labels_list,\n",
    "        centers_list,\n",
    "        shapes_list,\n",
    "        angles_deg_list,\n",
    "        sizes_list,\n",
    "        colors_list,\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_frames(\n",
    "    num_frames,\n",
    "    center,\n",
    "    angle_deg,\n",
    "    canvas_size,\n",
    "    shape,\n",
    "    size,\n",
    "    color,\n",
    "    step_size=0.5,\n",
    "):\n",
    "    frames = np.zeros((num_frames, canvas_size[0], canvas_size[1], 3))\n",
    "    angle_rad = np.radians(angle_deg)\n",
    "    direction = np.array([np.cos(angle_rad), -np.sin(angle_rad)]) * step_size\n",
    "\n",
    "    center = center.copy()\n",
    "\n",
    "    for i in range(num_frames):\n",
    "        canvas = np.ones((canvas_size[0], canvas_size[1], 3), dtype=np.uint8) * 255\n",
    "\n",
    "        if shape == \"circle\":\n",
    "            cv2.circle(canvas, tuple(center.astype(int)), size, color, -1)\n",
    "        elif shape == \"triangle\":\n",
    "            points = np.array(\n",
    "                [\n",
    "                    [center[0], center[1]],\n",
    "                    [center[0] + size, center[1]],\n",
    "                    [center[0] + size // 2, center[1] - size],\n",
    "                ]\n",
    "            )\n",
    "            points = points.reshape((-1, 1, 2)).astype(int)\n",
    "            cv2.fillPoly(canvas, [points], color=color)\n",
    "        elif shape == \"square\":\n",
    "            top_left = (int(center[0] - size // 2), int(center[1] - size // 2))\n",
    "            bottom_right = (int(center[0] + size // 2), int(center[1] + size // 2))\n",
    "            cv2.rectangle(canvas, top_left, bottom_right, color, -1)\n",
    "\n",
    "        frames[i] = canvas\n",
    "\n",
    "        # Update the center based on the direction and step size.\n",
    "        center += direction\n",
    "\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovingShapesDataset(Dataset):\n",
    "    def __init__(self, num_samples, num_frames, transform=None, canvas_size=(64, 64)):\n",
    "        self.num_samples = num_samples\n",
    "        self.num_frames = num_frames\n",
    "        self.canvas_size = canvas_size\n",
    "        (\n",
    "            self.labels,\n",
    "            self.centers,\n",
    "            self.shapes,\n",
    "            self.angles_deg,\n",
    "            self.sizes,\n",
    "            self.colors,\n",
    "        ) = generate_dataset(num_samples)\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label, center, shape, angle_deg, size, color = (\n",
    "            self.labels[idx],\n",
    "            self.centers[idx],\n",
    "            self.shapes[idx],\n",
    "            self.angles_deg[idx],\n",
    "            self.sizes[idx],\n",
    "            self.colors[idx],\n",
    "        )\n",
    "        frames = generate_frames(\n",
    "            self.num_frames, center, angle_deg, self.canvas_size, shape, size, color\n",
    "        )\n",
    "        frames = torch.from_numpy(frames).float() / 255.0\n",
    "        if self.transform:\n",
    "            frames, label = self.transform((frames, label))\n",
    "        return (\n",
    "            frames.permute(0, 3, 1, 2),\n",
    "            np.array(label, dtype=np.float32),\n",
    "            center,\n",
    "        )  # center is added for plotting purposes, you are not allowed to use it in the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MovingShapesDataset(num_samples=100000, num_frames=20)\n",
    "val_dataset = MovingShapesDataset(num_samples=1000, num_frames=20)\n",
    "test_dataset = MovingShapesDataset(num_samples=1000, num_frames=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = random.randint(0, len(train_dataset) - 1)\n",
    "sample_data, sample_label, sample_initial_position = train_dataset[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani = animate_datapoint_with_direction(\n",
    "    sample_data, sample_label, sample_initial_position, pred=(0.5, 0)\n",
    ")\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1\n",
    "\n",
    "#TODO Define CNN model to predict the angle of movement. You are encouraged to use the models from torchvision. You can also use the models from the previous lab. Do not forget to change the output layer dimension. And using the proper training scripts from the previous labs, train the model. How the model is doing? \n",
    "\n",
    "## Answer\n",
    "\n",
    "The model is still able to learn something from the training data. This makes sense since even before the popularity of recurrent models, there has been some success in using traditional modeling techniques for data with time dependence or order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "        optimizer:torch.optim.Optimizer, \n",
    "        loss: torch.nn.Module, \n",
    "        model: torch.nn.Module, \n",
    "        train_loader: DataLoader\n",
    "):\n",
    "    total_loss = 0\n",
    "    total_items = 0\n",
    "    model.train(True)\n",
    "\n",
    "    for inputs, labels, _ in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss_t = loss(outputs, labels)\n",
    "        loss_t.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        n_items = len(inputs)\n",
    "        total_loss += loss_t.item() * n_items\n",
    "        total_items += n_items\n",
    "\n",
    "    return total_loss / total_items\n",
    "\n",
    "def validate_epoch(\n",
    "        loss: torch.nn.Module, \n",
    "        model: torch.nn.Module, \n",
    "        val_loader: DataLoader\n",
    "):\n",
    "    total_loss = 0\n",
    "    total_items = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, _ in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            n_items = len(inputs)\n",
    "            total_loss += loss(outputs, labels).item() * n_items\n",
    "            total_items += n_items\n",
    "\n",
    "    return total_loss / total_items\n",
    "\n",
    "\n",
    "def training_loop(num_epoch, model, optimizer, loss, train_loader, val_loader):\n",
    "    best_val_loss = np.inf\n",
    "    best_model = None\n",
    "\n",
    "    train_losses = list()\n",
    "    val_losses = list()\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        train_loss = train_epoch(optimizer, loss, model, train_loader)\n",
    "        val_loss = validate_epoch(loss, model, val_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_model = copy.deepcopy(model)\n",
    "            best_val_loss = val_loss\n",
    "        print(f\"epoch {epoch + 1}: loss: {train_loss:0.4f} val loss: {val_loss:0.4f}\")\n",
    "\n",
    "    return best_model, train_losses, val_losses\n",
    "\n",
    "\n",
    "def predict(model: torch.nn.Module, test_loader: DataLoader):\n",
    "    with torch.no_grad():\n",
    "        true = []\n",
    "        pred = []\n",
    "        for inputs, labels, _ in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            predictions = outputs\n",
    "\n",
    "            true.append(labels)\n",
    "            pred.append(predictions)\n",
    "\n",
    "    return torch.cat(true).cpu().numpy(), torch.cat(pred).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True,\n",
    "    generator=torch.Generator(device=device)\n",
    ")\n",
    "valid_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(torch.nn.Module):\n",
    "    def __init__(self, num_channels=3, num_outputs=2, n_frames=20, input_shape=(64, 64)):\n",
    "        super().__init__()\n",
    "\n",
    "        n_conv_layers = 4\n",
    "        max_pool_divisor = 2 ** n_conv_layers\n",
    "\n",
    "        self.conv_layer1 = self._conv_layer_set(num_channels, 16)\n",
    "        self.conv_layer2 = self._conv_layer_set(16, 32)\n",
    "        self.conv_layer3 = self._conv_layer_set(32, 64)\n",
    "        self.conv_layer4 = self._conv_layer_set(64, 128)\n",
    "        flat_shape = (\n",
    "            128 * n_frames *\n",
    "            input_shape[0] // max_pool_divisor * \n",
    "            input_shape[1] // max_pool_divisor\n",
    "        )\n",
    "        self.fc1 = nn.Linear(flat_shape, num_outputs)\n",
    "\n",
    "    def _conv_layer_set(self, in_c, out_c):\n",
    "        conv_layer = nn.Sequential(OrderedDict([\n",
    "            ('conv',nn.Conv2d(in_c, out_c, kernel_size=3, padding=1)),\n",
    "            ('leakyrelu',nn.LeakyReLU()),\n",
    "            ('maxpool',nn.MaxPool2d(2)),\n",
    "        ]))\n",
    "        return conv_layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, num_frames, C, H, W = x.shape\n",
    "        x = x.view(batch_size * num_frames, C, H, W)\n",
    "\n",
    "        out = self.conv_layer1(x)\n",
    "        out = self.conv_layer2(out)\n",
    "        out = self.conv_layer3(out)\n",
    "        out = self.conv_layer4(out)\n",
    "\n",
    "        out = out.reshape((batch_size, -1))\n",
    "\n",
    "        out = self.fc1(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNModel()\n",
    "critereon = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "best_model, train_losses, val_losses = training_loop(20, model, optimizer, critereon, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(val_losses, label=\"val\")\n",
    "plt.title(\"MSE Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_true, test_pred = predict(best_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(test_true, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 2\n",
    "\n",
    "#TODO Define Recurrent neural network model to predict the angle of movement. And using the proper training scripts from the previous labs, train the model. How the model is doing? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can have a look at the following skeleton of a basic recurrent model in pytorch. Keep mind that is just a basic starting point. Have look at the [pytorch LSTM documentation](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html) and adding more layers, dropout, bidirectionality and so on\n",
    "\n",
    "## Answer\n",
    "\n",
    "The model seems to struggle to learn. I tried different configurations, even thought the configuration below is very simple. All of these configurations fail. It seems like learning the spatial characteristics of images is more important then learning the time dependencies between the frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, num_channels=3, hidden_size=128, output_size=2, num_layers=3, input_shape=(64, 64)):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        input_size = num_channels * input_shape[0] * input_shape[1]\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(2 * hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, num_frames, C, H, W = x.shape\n",
    "        x = x.reshape(batch_size, num_frames, C * H * W)\n",
    "\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1]\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel(hidden_size=256)\n",
    "critereon = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "best_model, train_losses, val_losses = training_loop(20, model, optimizer, critereon, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_true, test_pred = predict(best_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(val_losses, label=\"val\")\n",
    "plt.title(\"MSE Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(test_true, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 3\n",
    "\n",
    "#TODO Define a CNN + LSTM model to predict the angle of movement. You should do so by passing the features learned from the CNN model you have defined to LSTM module. In another words, you can insert a LSTM layer in between the conv layers and fully connected layers in the CNN model you have defined. This should learn the temporal features in between the frames. Does this model achieve better results? \n",
    "\n",
    "## Answer\n",
    "\n",
    "The model is able to achieve better performance than the first two models. Being able to extract spatial features and being able to correlate the time dependency between these spatial features allows the network to be able to learn more about the input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLSTMModel(torch.nn.Module):\n",
    "    def __init__(self, num_channels=3, num_outputs=2, hidden_size=128, lstm_layers=1, input_shape=(64, 64)):\n",
    "        super().__init__()\n",
    "\n",
    "        n_conv_layers = 4\n",
    "        max_pool_divisor = 2 ** n_conv_layers\n",
    "\n",
    "        self.conv_layer1 = self._conv_layer_set(num_channels, 16)\n",
    "        self.conv_layer2 = self._conv_layer_set(16, 32)\n",
    "        self.conv_layer3 = self._conv_layer_set(32, 64)\n",
    "        self.conv_layer4 = self._conv_layer_set(64, 128)\n",
    "        flat_shape = (\n",
    "            128 *\n",
    "            input_shape[0] // max_pool_divisor * \n",
    "            input_shape[1] // max_pool_divisor\n",
    "        )\n",
    "        self.lstm = nn.LSTM(flat_shape, hidden_size, lstm_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc1 = nn.Linear(hidden_size * 2, num_outputs)\n",
    "\n",
    "    def _conv_layer_set(self, in_c, out_c):\n",
    "        conv_layer = nn.Sequential(OrderedDict([\n",
    "            ('conv',nn.Conv2d(in_c, out_c, kernel_size=3, padding=1)),\n",
    "            ('leakyrelu',nn.LeakyReLU()),\n",
    "            ('maxpool',nn.MaxPool2d(2)),\n",
    "        ]))\n",
    "        return conv_layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, num_frames, C, H, W = x.shape\n",
    "        x = x.view(batch_size * num_frames, C, H, W)\n",
    "\n",
    "        out = self.conv_layer1(x)\n",
    "        out = self.conv_layer2(out)\n",
    "        out = self.conv_layer3(out)\n",
    "        out = self.conv_layer4(out)\n",
    "\n",
    "        out = out.reshape((batch_size, num_frames, -1))\n",
    "        out, _ = self.lstm(out)\n",
    "\n",
    "        out = self.fc1(out[:, -1])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNLSTMModel()\n",
    "critereon = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "best_model, train_losses, val_losses = training_loop(20, model, optimizer, critereon, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_true, test_pred = predict(best_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(val_losses, label=\"val\")\n",
    "plt.title(\"MSE Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(test_true, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 4\n",
    "\n",
    "#TODO Define a ConvLSTM model to predict the angle of movement. You should have a look at the lecture to refresh your memory on the mechanisms behind this. Does this model achieve better results? \n",
    "\n",
    "## Answer\n",
    "\n",
    "Similar to the 3rd model, being able to have spatial features and time dependence enables the model to learn the features well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have included an [implementation of the ConvLSTM](https://github.com/ndrplz/ConvLSTM_pytorch/tree/master) for the convenience. You can use this as a building block in your ConvLSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, bias):\n",
    "        \"\"\"\n",
    "        Initialize ConvLSTM cell.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_dim: int\n",
    "            Number of channels of input tensor.\n",
    "        hidden_dim: int\n",
    "            Number of channels of hidden state.\n",
    "        kernel_size: (int, int)\n",
    "            Size of the convolutional kernel.\n",
    "        bias: bool\n",
    "            Whether or not to add the bias.\n",
    "        \"\"\"\n",
    "\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = kernel_size[0] // 2, kernel_size[1] // 2\n",
    "        self.bias = bias\n",
    "\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=self.input_dim + self.hidden_dim,\n",
    "            out_channels=4 * self.hidden_dim,\n",
    "            kernel_size=self.kernel_size,\n",
    "            padding=self.padding,\n",
    "            bias=self.bias,\n",
    "        )\n",
    "\n",
    "    def forward(self, input_tensor, cur_state):\n",
    "        h_cur, c_cur = cur_state\n",
    "\n",
    "        combined = torch.cat(\n",
    "            [input_tensor, h_cur], dim=1\n",
    "        )  # concatenate along channel axis\n",
    "\n",
    "        combined_conv = self.conv(combined)\n",
    "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
    "        i = torch.sigmoid(cc_i)\n",
    "        f = torch.sigmoid(cc_f)\n",
    "        o = torch.sigmoid(cc_o)\n",
    "        g = torch.tanh(cc_g)\n",
    "\n",
    "        c_next = f * c_cur + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "\n",
    "        return h_next, c_next\n",
    "\n",
    "    def init_hidden(self, batch_size, image_size):\n",
    "        height, width = image_size\n",
    "        return (\n",
    "            torch.zeros(\n",
    "                batch_size,\n",
    "                self.hidden_dim,\n",
    "                height,\n",
    "                width,\n",
    "                device=self.conv.weight.device,\n",
    "            ),\n",
    "            torch.zeros(\n",
    "                batch_size,\n",
    "                self.hidden_dim,\n",
    "                height,\n",
    "                width,\n",
    "                device=self.conv.weight.device,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "\n",
    "class ConvLSTM(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters:\n",
    "        input_dim: Number of channels in input\n",
    "        hidden_dim: Number of hidden channels\n",
    "        kernel_size: Size of kernel in convolutions\n",
    "        num_layers: Number of LSTM layers stacked on each other\n",
    "        batch_first: Whether or not dimension 0 is the batch or not\n",
    "        bias: Bias or no bias in Convolution\n",
    "        return_all_layers: Return the list of computations for all layers\n",
    "        Note: Will do same padding.\n",
    "\n",
    "    Input:\n",
    "        A tensor of size B, T, C, H, W or T, B, C, H, W\n",
    "    Output:\n",
    "        A tuple of two lists of length num_layers (or length 1 if return_all_layers is False).\n",
    "            0 - layer_output_list is the list of lists of length T of each output\n",
    "            1 - last_state_list is the list of last states\n",
    "                    each element of the list is a tuple (h, c) for hidden state and memory\n",
    "    Example:\n",
    "        >> x = torch.rand((32, 10, 64, 128, 128))\n",
    "        >> convlstm = ConvLSTM(64, 16, 3, 1, True, True, False)\n",
    "        >> _, last_states = convlstm(x)\n",
    "        >> h = last_states[0][0]  # 0 for layer index, 0 for h index\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        hidden_dim,\n",
    "        kernel_size,\n",
    "        num_layers,\n",
    "        batch_first=False,\n",
    "        bias=True,\n",
    "        return_all_layers=False,\n",
    "    ):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "\n",
    "        self._check_kernel_size_consistency(kernel_size)\n",
    "\n",
    "        # Make sure that both `kernel_size` and `hidden_dim` are lists having len == num_layers\n",
    "        kernel_size = self._extend_for_multilayer(kernel_size, num_layers)\n",
    "        hidden_dim = self._extend_for_multilayer(hidden_dim, num_layers)\n",
    "        if not len(kernel_size) == len(hidden_dim) == num_layers:\n",
    "            raise ValueError(\"Inconsistent list length.\")\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = batch_first\n",
    "        self.bias = bias\n",
    "        self.return_all_layers = return_all_layers\n",
    "\n",
    "        cell_list = []\n",
    "        for i in range(0, self.num_layers):\n",
    "            cur_input_dim = self.input_dim if i == 0 else self.hidden_dim[i - 1]\n",
    "\n",
    "            cell_list.append(\n",
    "                ConvLSTMCell(\n",
    "                    input_dim=cur_input_dim,\n",
    "                    hidden_dim=self.hidden_dim[i],\n",
    "                    kernel_size=self.kernel_size[i],\n",
    "                    bias=self.bias,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.cell_list = nn.ModuleList(cell_list)\n",
    "\n",
    "    def forward(self, input_tensor, hidden_state=None):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_tensor: todo\n",
    "            5-D Tensor either of shape (t, b, c, h, w) or (b, t, c, h, w)\n",
    "        hidden_state: todo\n",
    "            None. todo implement stateful\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        last_state_list, layer_output\n",
    "        \"\"\"\n",
    "        if not self.batch_first:\n",
    "            # (t, b, c, h, w) -> (b, t, c, h, w)\n",
    "            input_tensor = input_tensor.permute(1, 0, 2, 3, 4)\n",
    "\n",
    "        b, _, _, h, w = input_tensor.size()\n",
    "\n",
    "        # Implement stateful ConvLSTM\n",
    "        if hidden_state is not None:\n",
    "            raise NotImplementedError()\n",
    "        else:\n",
    "            # Since the init is done in forward. Can send image size here\n",
    "            hidden_state = self._init_hidden(batch_size=b, image_size=(h, w))\n",
    "\n",
    "        layer_output_list = []\n",
    "        last_state_list = []\n",
    "\n",
    "        seq_len = input_tensor.size(1)\n",
    "        cur_layer_input = input_tensor\n",
    "\n",
    "        for layer_idx in range(self.num_layers):\n",
    "            h, c = hidden_state[layer_idx]\n",
    "            output_inner = []\n",
    "            for t in range(seq_len):\n",
    "                h, c = self.cell_list[layer_idx](\n",
    "                    input_tensor=cur_layer_input[:, t, :, :, :], cur_state=[h, c]\n",
    "                )\n",
    "                output_inner.append(h)\n",
    "\n",
    "            layer_output = torch.stack(output_inner, dim=1)\n",
    "            cur_layer_input = layer_output\n",
    "\n",
    "            layer_output_list.append(layer_output)\n",
    "            last_state_list.append([h, c])\n",
    "\n",
    "        if not self.return_all_layers:\n",
    "            layer_output_list = layer_output_list[-1:]\n",
    "            last_state_list = last_state_list[-1:]\n",
    "\n",
    "        return layer_output_list, last_state_list\n",
    "\n",
    "    def _init_hidden(self, batch_size, image_size):\n",
    "        init_states = []\n",
    "        for i in range(self.num_layers):\n",
    "            init_states.append(self.cell_list[i].init_hidden(batch_size, image_size))\n",
    "        return init_states\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_kernel_size_consistency(kernel_size):\n",
    "        if not (\n",
    "            isinstance(kernel_size, tuple)\n",
    "            or (\n",
    "                isinstance(kernel_size, list)\n",
    "                and all([isinstance(elem, tuple) for elem in kernel_size])\n",
    "            )\n",
    "        ):\n",
    "            raise ValueError(\"`kernel_size` must be tuple or list of tuples\")\n",
    "\n",
    "    @staticmethod\n",
    "    def _extend_for_multilayer(param, num_layers):\n",
    "        if not isinstance(param, list):\n",
    "            param = [param] * num_layers\n",
    "        return param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTMModel(torch.nn.Module):\n",
    "    def __init__(self, num_channels=3, num_outputs=2, hidden_size=32, num_layers=1, input_shape=(64, 64)):\n",
    "        super().__init__()\n",
    "\n",
    "        self.convlstm = ConvLSTM(\n",
    "            input_dim=num_channels,\n",
    "            hidden_dim=hidden_size,\n",
    "            kernel_size=(3, 3),\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bias=True,\n",
    "            return_all_layers=False\n",
    "        )\n",
    "        flat_shape = hidden_size * input_shape[0] * input_shape[1]\n",
    "        self.fc1 = nn.Linear(flat_shape, num_outputs)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        (out, ), _  = self.convlstm(x)\n",
    "        out = out[:, -1].view(out.size(0), -1)\n",
    "\n",
    "        out = self.fc1(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=50, \n",
    "    shuffle=True,\n",
    "    generator=torch.Generator(device=device)\n",
    ")\n",
    "valid_loader = DataLoader(val_dataset, batch_size=50)\n",
    "test_loader = DataLoader(test_dataset, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvLSTMModel(hidden_size=16, num_layers=3)\n",
    "critereon = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "best_model, train_losses, val_losses = training_loop(20, model, optimizer, critereon, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_true, test_pred = predict(best_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(val_losses, label=\"val\")\n",
    "plt.title(\"MSE Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(test_true, test_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
