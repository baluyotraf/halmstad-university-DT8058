{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name: Raffaello Baluyot\n",
    "## Course: DT8058"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1 style=\"font-size:40px;\">Image Classification using CNNs</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the *Fourth* lab for Deep Learning!\n",
    "\n",
    "In this lab an CNN network to classify RGB images. Image classification refers to classify classes from images. This labs the *dataset* consist of multiple images where each image have a target label for classification.\n",
    "\n",
    "Good luck!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import os\n",
    "import imageio\n",
    "import torchvision\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import OrderedDict\n",
    "import copy\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In case you have uploaded a zip file unzip it first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "torch.set_default_device(device)\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip ../data/FlyingObjectDataset_10K.zip -d ../data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then lets define the ```path``` to the dataset. Make sure you explore the directories of the dataset and get familiar with it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_img_dir = \"../data/FlyingObjectDataset_10K/training\"\n",
    "validation_img_dir = \"../data/FlyingObjectDataset_10K/validation\"\n",
    "testing_img_dir = \"../data/FlyingObjectDataset_10K/testing\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally we will start using ```tensorboard```. Use of tensorboard is optional, but we recommend the students to use it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy_train_loss, _ = torch.sort(torch.rand(100) * 5, descending=True)\n",
    "# dummy_val_loss, _ = torch.sort(torch.rand(100) * 6, descending=True )\n",
    "# dummy_train_acc, _ = torch.sort(torch.rand(100) * 100)\n",
    "# dummy_val_acc, _ = torch.sort(torch.rand(100) * 80)\n",
    "# for i in range(100): \n",
    "#     writer.add_scalar('Loss/Train', dummy_train_loss[i], i)\n",
    "#     writer.add_scalar('Loss/Val', dummy_val_loss[i], i)\n",
    "#     writer.add_scalar('Acc/Train', dummy_train_acc[i], i)\n",
    "#     writer.add_scalar('Acc/Val', dummy_val_acc[i], i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please make sure to read the [doc](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html) to understand how to correctly plot your ```losses``` and ```metrics``` to tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok now that we have the path to the tree different splits, lets start by defining our ```Dataset``` class!\n",
    "The main two methods we need to define when subclassing ```Dataset``` is ```__getitem__``` and ```__len__```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlyingObjects(torch.utils.data.Dataset):\n",
    "    \"\"\"Dataset to Flying Object Dataset for the classification task.\n",
    "       The label information is encoded on the filename, __extract_label will extract the label following the chosen granularity\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, root,fine_grained=False,transform=None):\n",
    "        super(FlyingObjects,self).__init__()\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.fine_grained = fine_grained\n",
    "\n",
    "        self.images = [os.path.join(dp,f) for dp, dn, fn in os.walk(os.path.expanduser(self.root+'/image')) for f in fn if f.endswith(\".png\")]\n",
    "        self.images.sort()\n",
    "        \n",
    "        self.classes = [\n",
    "            'square_red',\n",
    "            'square_green',\n",
    "            'square_blue',\n",
    "            'square_yellow',\n",
    "            'triangle_red',\n",
    "            'triangle_green',\n",
    "            'triangle_blue',\n",
    "            'triangle_yellow',\n",
    "            'circular_red',\n",
    "            'circular_green',\n",
    "            'circular_blue',\n",
    "            'circular_yellow'\n",
    "        ] if self.fine_grained else [\n",
    "            'square',\n",
    "            'triangle',\n",
    "            'circular',\n",
    "            'background']\n",
    "        self.labels = [self.__extract_label(f) for f in self.images]\n",
    "    \n",
    "\n",
    "    def get_classes(self):\n",
    "        return self.classes\n",
    "    \n",
    "    \n",
    "    def __extract_label(self, image_file):\n",
    "        \"\"\"Extract label from image_file name\"\"\"\n",
    "        path, img_name = os.path.split(image_file)\n",
    "        names = img_name.split(\".\")[0].split(\"_\")\n",
    "\n",
    "        currLabel = names[1] + \"_\" + names[2] if self.fine_grained else names[1]\n",
    "\n",
    "        if currLabel in self.classes:\n",
    "            label = self.classes.index(currLabel)\n",
    "        else:\n",
    "            raise ValueError(\"ERROR: Label \" + str(currLabel) + \" is not defined!\")\n",
    "        return label\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # get data\n",
    "        x = imageio.imread(self.images[index])\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        else:\n",
    "            x = torch.from_numpy(x)\n",
    "        x = x.float()\n",
    "   \n",
    "        # get label\n",
    "        y = self.labels[index]\n",
    "        #y = np.eye(len(self.get_classes()))[y]\n",
    "        #y = torch.tensor(y)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define our transformations. Note that not all transformations are considered ```Data Augmentation```.\n",
    "The following transformations are used to convert our data to ```Tensor``` and resize our images to the desired size!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize((64, 64)), \n",
    "])\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize((64, 64))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "Define the three dataloaders for the three splits: ```train```, ```validation``` and ```test``` and visualize data from each split. A function to visualize the image with label is given. You are free to use it or make your own visualizaiton tools.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_with_labels(dataloader, title:str=None, nimages:int=10, nrows:int=2, fig_dimension=1,title_size=10, label_prefix=\"Label: \", label_transform = lambda l:l):\n",
    "    \"\"\"Creates a grid of images with/without labels.\n",
    "\n",
    "    :param title: str:  (Default value = None)\n",
    "    :param nimages: int:  (Default value = 10)\n",
    "    :param nrows: int:  (Default value = 2)\n",
    "    :param fig_dimension: Default value = 1)\n",
    "    :param data:\"tensor\": \n",
    "    :param labels:\"tensor\":  (Default value = None)\n",
    "    :param title:str:  (Default value = None)\n",
    "    :param nimages:int:  (Default value = 10)\n",
    "    :param nrows:int:  (Default value = 2)\n",
    "\n",
    "    \"\"\"\n",
    "    indices = np.random.choice(np.arange(len(dataloader.dataset)), nimages, replace=False)\n",
    "    data, labels = zip(*[dataloader.dataset[i] for i in indices])\n",
    "    data = torch.stack(list(data)).permute(0,2,3,1)\n",
    "\n",
    "    image_ratio = data[0].shape[0] /data[0].shape[1]\n",
    "    if len(data)< nimages:\n",
    "        nimages = len(data)\n",
    " \n",
    "    columns = math.ceil(nimages/nrows)\n",
    "    \n",
    "    if nrows*columns > nimages:\n",
    "        nrows = math.ceil(nimages/columns)\n",
    "    \n",
    "    fig = plt.figure(figsize=(fig_dimension*columns,1.4*fig_dimension*nrows*image_ratio))\n",
    "    for i in range(0, nimages):\n",
    "        ax = fig.add_subplot(nrows, columns, i+1)\n",
    "        ax.imshow(data[i])\n",
    "        ax.set_xlabel(f\"{label_prefix}{label_transform(labels[i])}\") if labels is not None else None\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.grid(False)\n",
    "\n",
    "    if labels is None:\n",
    "        fig.suptitle(title,x=0.5, y=.95, size=title_size) \n",
    "        \n",
    "        fig.subplots_adjust(\n",
    "            left=0,\n",
    "            right=0.9,\n",
    "            top=0.9,\n",
    "            bottom=0,\n",
    "            wspace=0.1,\n",
    "            hspace=-0.45\n",
    "        )\n",
    "    else:\n",
    "        fig.suptitle(title) #,x=0.45, y=.95\n",
    "        \n",
    "        fig.subplots_adjust(\n",
    "            #left=0,\n",
    "            #right=1,\n",
    "            top=0.9,#+((nrows-1)*0.045),\n",
    "            #bottom=0,\n",
    "            wspace=0,\n",
    "            #hspace=0\n",
    "        )\n",
    "        \n",
    "    #plt.tight_layout(h_pad=0,w_pad=0)\n",
    "    fig.tight_layout(pad=0, h_pad=0,w_pad=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    FlyingObjects(root=training_img_dir, transform=train_transform), \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True,\n",
    "    generator=torch.Generator(device='cuda')\n",
    ")\n",
    "valid_loader = DataLoader(FlyingObjects(root=validation_img_dir, transform=test_transform), batch_size=batch_size)\n",
    "test_loader = DataLoader(FlyingObjects(root=testing_img_dir, transform=test_transform), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_with_labels(train_loader, nimages=15, nrows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_with_labels(valid_loader, nimages=15, nrows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_with_labels(test_loader, nimages=15, nrows=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start with a very simple network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(torch.nn.Module):\n",
    "    def __init__(self,num_channels, num_classes, input_shape=(64,64)):\n",
    "        super(SimpleModel,self).__init__()\n",
    "        self.conv_layer1 = self._conv_layer_set(num_channels, 32)\n",
    "        self.conv_layer2 = self._conv_layer_set(32, 64)\n",
    "        self.fc1 = nn.Linear(64*input_shape[1]//4*input_shape[1]//4, 64)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        self.act = nn.ReLU(inplace=False)\n",
    "        \n",
    "    def _conv_layer_set(self, in_c, out_c):\n",
    "        conv_layer = nn.Sequential(OrderedDict([\n",
    "            ('conv',nn.Conv2d(in_c, out_c, kernel_size=3, padding=1)),\n",
    "            ('leakyrelu',nn.LeakyReLU()),\n",
    "            ('maxpool',nn.MaxPool2d(2)),\n",
    "        ]))\n",
    "        return conv_layer\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv_layer1(x)\n",
    "        out = self.conv_layer2(out)\n",
    "       \n",
    "        out = out.view(out.size(0), -1)\n",
    "\n",
    "        out = self.fc1(out)\n",
    "        # out = self.act(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "Get inspired on the code you did on the previous lab and create your ```train function```. It might be useful to think about having a ```predict``` function too. Check the code of the previous lab if you need ideas!\n",
    "\n",
    "Do not forget, to train you need an ```optimizer```, ```loss function``` and an instance of your ```model```! If you need more inspiration check [here](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "        optimizer:torch.optim.Optimizer, \n",
    "        loss: torch.nn.Module, \n",
    "        model: torch.nn.Module, \n",
    "        train_loader: DataLoader\n",
    "):\n",
    "    total_loss = 0\n",
    "    total_items = 0\n",
    "    model.train(True)\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss_t = loss(outputs, labels)\n",
    "        loss_t.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        n_items = len(inputs)\n",
    "        total_loss += loss_t.item() * n_items\n",
    "        total_items += n_items\n",
    "\n",
    "    return total_loss / total_items\n",
    "\n",
    "def validate_epoch(\n",
    "        loss: torch.nn.Module, \n",
    "        model: torch.nn.Module, \n",
    "        val_loader: DataLoader\n",
    "):\n",
    "    total_loss = 0\n",
    "    total_items = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            n_items = len(inputs)\n",
    "            total_loss += loss(outputs, labels).item() * n_items\n",
    "            total_items += n_items\n",
    "\n",
    "    return total_loss / total_items\n",
    "\n",
    "\n",
    "def training_loop(num_epoch, model, optimizer, loss, train_loader, val_loader):\n",
    "    best_val_loss = np.inf\n",
    "    best_model = None\n",
    "\n",
    "    train_losses = list()\n",
    "    val_losses = list()\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        train_loss = train_epoch(optimizer, loss, model, train_loader)\n",
    "        val_loss = validate_epoch(loss, model, val_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_model = copy.deepcopy(model)\n",
    "            best_val_loss = val_loss\n",
    "        print(f\"epoch {epoch + 1}: loss: {train_loss:0.4f} val loss: {val_loss:0.4f}\")\n",
    "\n",
    "    return best_model, train_losses, val_losses\n",
    "\n",
    "\n",
    "def predict(model: torch.nn.Module, test_loader: DataLoader):\n",
    "    with torch.no_grad():\n",
    "        true = []\n",
    "        pred = []\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            predictions = outputs.argmax(-1)\n",
    "\n",
    "            true.append(labels)\n",
    "            pred.append(predictions)\n",
    "\n",
    "    return torch.cat(true).cpu().numpy(), torch.cat(pred).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "Now that you have your train function. Train the network until it overfits. Which ```hyperparameters``` allowed you to overfit?\n",
    "\n",
    "## Answer\n",
    "\n",
    "It's hard to say which ```hyperparameters``` caused the overfitting. The size of the network played a role in this, since a small network will underfit and will not have enough complexity to memorize the input. Training epoch as well as the optimization algorithm also played a role in overfitting.\n",
    "\n",
    "After playing with the dataset for a while, it looks like the training distribution is hard for the network to generalize to the validation and testing data as it is. That's why adding transformations improves the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help you visualize the results we provide a ```confusion matrix function```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix(y_true, y_pred, classes):\n",
    "    cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cf_matrix,display_labels=classes)\n",
    "    disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleModel(num_channels=3, num_classes=3).to(device)\n",
    "critereon = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "best_model, train_losses, val_losses = training_loop(10, model, optimizer, critereon, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(val_losses, label=\"val\")\n",
    "plt.title(\"Cross Entropy Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_true, test_pred = predict(best_model, test_loader)\n",
    "matrix(test_true, test_pred, train_loader.dataset.classes[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "Go through the [doc](https://pytorch.org/vision/stable/transforms.html) about data augmentation transformations and use some (Try at least 5 augmentations) in your pipeline. Did the ones you try improve your model? Why? \n",
    "\n",
    "Along with ```torchvision``` you can also expore ```https://albumentations.ai/``` for advanced augmentation. \n",
    "\n",
    "## Answer\n",
    "\n",
    "The augmentations improve the model in the sense that now it does not overfit. However it still does not learn as much. It improved the model because the transformations increased the distribution covered by the dataset, hence now the model has a hard time learning it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.RandomChoice([\n",
    "        torchvision.transforms.RandomRotation((0, 0), fill=1),\n",
    "        torchvision.transforms.RandomRotation((180, 180), fill=1),\n",
    "        torchvision.transforms.RandomRotation((90, 90), fill=1),\n",
    "        torchvision.transforms.RandomRotation((270, 270), fill=1),\n",
    "    ]),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomVerticalFlip(),\n",
    "    torchvision.transforms.Resize((64, 64)), \n",
    "])\n",
    "\n",
    "train_loader = DataLoader(FlyingObjects(root=training_img_dir, transform=train_transform), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_with_labels(train_loader, nimages=15, nrows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleModel(num_channels=3, num_classes=3).to(device)\n",
    "critereon = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "best_model, train_losses, val_losses = training_loop(20, model, optimizer, critereon, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(val_losses, label=\"val\")\n",
    "plt.title(\"Cross Entropy Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_true, test_pred = predict(best_model, test_loader)\n",
    "matrix(test_true, test_pred, train_loader.dataset.classes[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "\n",
    "Redo the previous questions with an image size of ```128x128```. Make sure to note what changed and why. If you decided to use tensorboard, compare both versions on ```Tensorboard``` plots.\n",
    "\n",
    "## Answer\n",
    "\n",
    "The model can now overfit even with the augmentations present. I guess the model has more details to work with and it was able to pick up some of the features from the higher resolution images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.RandomChoice([\n",
    "        torchvision.transforms.RandomRotation((0, 0), fill=1),\n",
    "        torchvision.transforms.RandomRotation((180, 180), fill=1),\n",
    "        torchvision.transforms.RandomRotation((90, 90), fill=1),\n",
    "        torchvision.transforms.RandomRotation((270, 270), fill=1),\n",
    "    ]),\n",
    "    torchvision.transforms.RandomChoice([\n",
    "        torchvision.transforms.Pad(0, fill=1),\n",
    "        *[\n",
    "            torchvision.transforms.Pad(i, fill=1)\n",
    "            for i in [3, 6, 9]\n",
    "        ],\n",
    "        *[\n",
    "            torchvision.transforms.CenterCrop((128-i, 128-i))\n",
    "            for i in [3, 6, 9]\n",
    "        ],\n",
    "    ]),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomVerticalFlip(),\n",
    "    torchvision.transforms.Resize((128, 128)), \n",
    "])\n",
    "\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize((128, 128))\n",
    "])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    FlyingObjects(root=training_img_dir, transform=train_transform), \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True,\n",
    "    generator=torch.Generator(device=device)\n",
    ")\n",
    "valid_loader = DataLoader(FlyingObjects(root=validation_img_dir, transform=test_transform), batch_size=batch_size)\n",
    "test_loader = DataLoader(FlyingObjects(root=testing_img_dir, transform=test_transform), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_with_labels(train_loader, nimages=15, nrows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleModel(num_channels=3, num_classes=3, input_shape=(128, 128)).to(device)\n",
    "critereon = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "best_model, train_losses, val_losses = training_loop(20, model, optimizer, critereon, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(val_losses, label=\"val\")\n",
    "plt.title(\"Cross Entropy Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_true, test_pred = predict(best_model, test_loader)\n",
    "matrix(test_true, test_pred, train_loader.dataset.classes[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "\n",
    "Once you have a good model for ```128x128``` without ```fine grain``` redo the experiments with ```fine grain```. How did the performance change? And why?\n",
    "\n",
    "## Answer\n",
    "\n",
    "The model performance has degraded. One, the problem is harder and so there's a lot of things for the model to be confused with. \n",
    "\n",
    "Another thing is that it takes the model a longer time to be able to arrive to an relatively acceptable performance during the training. This makes sense since it needs to learn to also separate the different colors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good 128x128 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepModel(torch.nn.Module):\n",
    "    def __init__(self,num_channels, num_classes, input_shape=(64,64)):\n",
    "        super().__init__()\n",
    "        self.conv_layer1 = self._conv_layer_set(num_channels, 16)\n",
    "        self.conv_layer2 = self._conv_layer_set(16, 32)\n",
    "        self.conv_layer3 = self._conv_layer_set(32, 64)\n",
    "        self.conv_layer4 = self._conv_layer_set(64, 128)\n",
    "        flat_shape = 128 * input_shape[0] // 2**4 * input_shape[1] // 2 ** 4\n",
    "        self.fc1 = nn.Linear(flat_shape, num_classes)\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        \n",
    "    def _conv_layer_set(self, in_c, out_c):\n",
    "        conv_layer = nn.Sequential(OrderedDict([\n",
    "            ('conv', nn.Conv2d(in_c, out_c, kernel_size=3, padding=1)),\n",
    "            ('leakyrelu', nn.LeakyReLU()),\n",
    "            ('maxpool', nn.MaxPool2d(2)),\n",
    "        ]))\n",
    "        return conv_layer\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv_layer1(x)\n",
    "        out = self.conv_layer2(out)\n",
    "        out = self.conv_layer3(out)\n",
    "        out = self.conv_layer4(out)\n",
    "       \n",
    "        out = out.view(out.size(0), -1)\n",
    "\n",
    "        out = self.drop(out)\n",
    "        out = self.fc1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepModel(num_channels=3, num_classes=3, input_shape=(128, 128)).to(device)\n",
    "critereon = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "best_model, train_losses, val_losses = training_loop(20, model, optimizer, critereon, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(val_losses, label=\"val\")\n",
    "plt.title(\"Cross Entropy Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_true, test_pred = predict(best_model, test_loader)\n",
    "matrix(test_true, test_pred, train_loader.dataset.classes[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_true, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Grained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    FlyingObjects(root=training_img_dir, transform=train_transform, fine_grained=True), \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True,\n",
    "    generator=torch.Generator(device=device)\n",
    ")\n",
    "valid_loader = DataLoader(FlyingObjects(root=validation_img_dir, transform=test_transform, fine_grained=True), batch_size=batch_size)\n",
    "test_loader = DataLoader(FlyingObjects(root=testing_img_dir, transform=test_transform, fine_grained=True), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepModel(num_channels=3, num_classes=12, input_shape=(128, 128)).to(device)\n",
    "critereon = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "best_model, train_losses, val_losses = training_loop(100, model, optimizer, critereon, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(val_losses, label=\"val\")\n",
    "plt.title(\"Cross Entropy Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_true, test_pred = predict(best_model, test_loader)\n",
    "matrix(test_true, test_pred, [\"\".join(w[0] for w in c.split(\"_\")) for c in train_loader.dataset.classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_true, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7\n",
    "Change the model and dataset to predict both shape and color of the flying object separately. Hint: The model may have 2 output heads. One should predict the color and another should predict the shape. Report the changes you made along with the results. \n",
    "\n",
    "## Answer\n",
    "\n",
    "Made the model large to accommodate two heads. Though while the performance of the two headed model for the individual task is fine, combining the result does not make it better than the previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlyingObjectsMulti(torch.utils.data.Dataset):\n",
    "    \"\"\"Dataset to Flying Object Dataset for the classification task.\n",
    "       The label information is encoded on the filename, __extract_label will extract the label following the chosen granularity\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, root, transform=None):\n",
    "        super().__init__()\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "\n",
    "        self.images = [os.path.join(dp,f) for dp, dn, fn in os.walk(os.path.expanduser(self.root+'/image')) for f in fn if f.endswith(\".png\")]\n",
    "        self.images.sort()\n",
    "        \n",
    "        self.color_classes = [\n",
    "            \"red\",\n",
    "            \"green\",\n",
    "            \"blue\",\n",
    "            \"yellow\",\n",
    "        ]\n",
    "        self.shape_classes = [\n",
    "            \"square\",\n",
    "            \"triangle\",\n",
    "            \"circular\",\n",
    "        ]\n",
    "        self.labels = [self.__extract_label(f) for f in self.images]\n",
    "    \n",
    "    def __extract_label(self, image_file):\n",
    "        \"\"\"Extract label from image_file name\"\"\"\n",
    "        path, img_name = os.path.split(image_file)\n",
    "        names = img_name.split(\".\")[0].split(\"_\")\n",
    "\n",
    "        shape = names[1]\n",
    "        color = names[2]\n",
    "\n",
    "        shape_class = self.shape_classes.index(shape)\n",
    "        color_class = self.color_classes.index(color)\n",
    "\n",
    "        return torch.LongTensor([shape_class, color_class])\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # get data\n",
    "        x = imageio.imread(self.images[index])\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        else:\n",
    "            x = torch.from_numpy(x)\n",
    "        x = x.float()\n",
    "   \n",
    "        # get label\n",
    "        y = self.labels[index]\n",
    "        #y = np.eye(len(self.get_classes()))[y]\n",
    "        #y = torch.tensor(y)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    FlyingObjectsMulti(root=training_img_dir, transform=train_transform), \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True,\n",
    "    generator=torch.Generator(device=device)\n",
    ")\n",
    "valid_loader = DataLoader(FlyingObjectsMulti(root=validation_img_dir, transform=test_transform), batch_size=batch_size)\n",
    "test_loader = DataLoader(FlyingObjectsMulti(root=testing_img_dir, transform=test_transform), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_with_labels(train_loader, nimages=15, nrows=3, label_transform=lambda l: l.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_multi(\n",
    "        optimizer:torch.optim.Optimizer, \n",
    "        losses: List[torch.nn.Module], \n",
    "        model: torch.nn.Module, \n",
    "        train_loader: DataLoader\n",
    "):\n",
    "    total_loss = 0\n",
    "    total_items = 0\n",
    "    model.train(True)\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        multi_loss = 0.0\n",
    "        for idx, loss in enumerate(losses):\n",
    "            multi_loss += loss(outputs[idx], labels[:, idx]) ** 2\n",
    "        multi_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        n_items = len(inputs)\n",
    "        total_loss += multi_loss.item() * n_items\n",
    "        total_items += n_items\n",
    "\n",
    "    return total_loss / total_items\n",
    "\n",
    "def validate_epoch_multi(\n",
    "        losses: List[torch.nn.Module], \n",
    "        model: torch.nn.Module, \n",
    "        val_loader: DataLoader\n",
    "):\n",
    "    total_loss = 0\n",
    "    total_items = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            multi_loss = 0.0\n",
    "            for idx, loss in enumerate(losses):\n",
    "                multi_loss += loss(outputs[idx], labels[:, idx]) ** 2\n",
    "\n",
    "            n_items = len(inputs)\n",
    "            total_loss += multi_loss.item() * n_items\n",
    "            total_items += n_items\n",
    "\n",
    "    return total_loss / total_items\n",
    "\n",
    "\n",
    "def training_loop_multi(num_epoch, model, optimizer, losses, train_loader, val_loader):\n",
    "    best_val_loss = np.inf\n",
    "    best_model = None\n",
    "\n",
    "    train_losses = list()\n",
    "    val_losses = list()\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        train_loss = train_epoch_multi(optimizer, losses, model, train_loader)\n",
    "        val_loss = validate_epoch_multi(losses, model, val_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_model = copy.deepcopy(model)\n",
    "            best_val_loss = val_loss\n",
    "        print(f\"epoch {epoch + 1}: loss: {train_loss:0.4f} val loss: {val_loss:0.4f}\")\n",
    "\n",
    "    return best_model, train_losses, val_losses\n",
    "\n",
    "\n",
    "def predict_multi(model: torch.nn.Module, test_loader: DataLoader):\n",
    "    with torch.no_grad():\n",
    "        true = []\n",
    "        pred = []\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            predictions = torch.stack([output.argmax(-1) for output in outputs], dim=-1)\n",
    "\n",
    "            true.append(labels)\n",
    "            pred.append(predictions)\n",
    "\n",
    "    return torch.cat(true).cpu().numpy(), torch.cat(pred).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepMultiModel(torch.nn.Module):\n",
    "    def __init__(self, num_channels: int, head_num_classes: List[int], input_shape=(64,64)):\n",
    "        super().__init__()\n",
    "        self.conv_layer1 = self._conv_layer_set(num_channels, 32)\n",
    "        self.conv_layer2 = self._conv_layer_set(32, 64)\n",
    "        self.conv_layer3 = self._conv_layer_set(64, 128)\n",
    "        self.conv_layer4 = self._conv_layer_set(128, 256)\n",
    "\n",
    "        flat_shape = 256 * input_shape[0] // 2**4 * input_shape[1] // 2 ** 4\n",
    "        self.fc1 = [nn.Linear(flat_shape, n) for n in head_num_classes]\n",
    "        self.drop = nn.Dropout(0.7)\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "    def _conv_layer_set(self, in_c, out_c):\n",
    "        conv_layer = nn.Sequential(OrderedDict([\n",
    "            ('conv', nn.Conv2d(in_c, out_c, kernel_size=3, padding=1)),\n",
    "            ('leakyrelu', nn.LeakyReLU()),\n",
    "            ('maxpool', nn.MaxPool2d(2)),\n",
    "        ]))\n",
    "        return conv_layer\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv_layer1(x)\n",
    "        out = self.conv_layer2(out)\n",
    "        out = self.conv_layer3(out)\n",
    "        out = self.conv_layer4(out)\n",
    "\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.drop(out)\n",
    "\n",
    "        # out = [conv(out) for conv in self.conv_layer4]\n",
    "        # out = [o.view(o.size(0), -1) for o in out]\n",
    "        # out = [fc(o) for fc, o in zip(self.fc1, out)]\n",
    "\n",
    "        out = [fc(out) for fc in self.fc1]\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepMultiModel(3, [3, 4], input_shape=(128, 128))\n",
    "critereon = [torch.nn.CrossEntropyLoss(), torch.nn.CrossEntropyLoss()]\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "best_model, train_losses, val_losses = training_loop_multi(100, model, optimizer, critereon, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(val_losses, label=\"val\")\n",
    "plt.title(\"Total Cross Entropy Losses\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_true, test_pred = predict_multi(best_model, test_loader)\n",
    "matrix(test_true[:, 0], test_pred[:, 0], train_loader.dataset.shape_classes)\n",
    "matrix(test_true[:, 1], test_pred[:, 1], train_loader.dataset.color_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_true[:, 0], test_pred[:, 0]))\n",
    "print(classification_report(test_true[:, 1], test_pred[:, 1]))\n",
    "print(classification_report(test_true[:, 0] * 10 + test_true[:, 1], test_pred[:, 0] * 10 + test_pred[:, 1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
